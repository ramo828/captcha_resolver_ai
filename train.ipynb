{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712a1bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 04:37:58.812957: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4780b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Veri setini yükleme\n",
    "data_path = \"data/captchas.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "column_names = ['Image_Path', 'Caption']  # Başlık sütunlarının listesini oluşturun\n",
    "\n",
    "df.columns = column_names  # DataFrame'e yeni başlık sütunlarını atayın\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff33f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resim dosyalarının konumları ve metinleri alın\n",
    "image_paths = df[\"Image_Path\"].values\n",
    "captions = df[\"Caption\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379f0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Resimleri yükleme ve ön işleme\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = keras.preprocessing.image.load_img(image_path, color_mode=\"grayscale\", target_size=(200, 70))\n",
    "    image = keras.preprocessing.image.img_to_array(image) / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c20c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = np.array([load_and_preprocess_image(path) for path in image_paths])\n",
    "\n",
    "# Metinleri vektörleştirme\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(captions)\n",
    "captions_encoded = tokenizer.texts_to_sequences(captions)\n",
    "captions_encoded = keras.preprocessing.sequence.pad_sequences(captions_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a13322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Veri kümesini eğitim ve test kümelerine ayırma\n",
    "train_images, test_images, train_captions, test_captions = train_test_split(\n",
    "    images, captions_encoded, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4d6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli oluşturma\n",
    "image_input = layers.Input(shape=(200, 70, 1), name=\"image_input\")\n",
    "image_conv = layers.Conv2D(32, (3, 3), activation=\"relu\")(image_input)\n",
    "image_pool = layers.MaxPooling2D((2, 2))(image_conv)\n",
    "image_flat = layers.Flatten()(image_pool)\n",
    "\n",
    "caption_input = layers.Input(shape=(captions_encoded.shape[1],), name=\"caption_input\")\n",
    "caption_embedding = layers.Embedding(len(tokenizer.word_index) + 1, 50)(caption_input)\n",
    "caption_flat = layers.Flatten()(caption_embedding)\n",
    "\n",
    "concatenated = layers.concatenate([image_flat, caption_flat])\n",
    "hidden = layers.Dense(64, activation=\"relu\")(concatenated)\n",
    "output = layers.Dense(captions_encoded.shape[1], activation=\"softmax\")(hidden)\n",
    "\n",
    "model = keras.models.Model(inputs=[image_input, caption_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc2751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli derleme\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54992268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 04:42:49.458541: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 55148544 exceeds 10% of free system memory.\n",
      "2023-07-19 04:42:49.704856: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 55148544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Modeli eğitme\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcaption_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_captions\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_captions\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:866\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m--> 866\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "# Modeli eğitme\n",
    "history = model.fit(\n",
    "    {\"image_input\": train_images, \"caption_input\": train_captions},\n",
    "    train_captions[:,-1],\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3347bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin performansını değerlendirme\n",
    "test_loss, test_accuracy = model.evaluate({\"image_input\": test_images, \"caption_input\": test_captions}, test_captions)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f069713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (AI)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
